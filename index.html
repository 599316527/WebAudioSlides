<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Making the Web Rock: Web Audio</title>

		<meta name="description" content="Web Audio talk">
		<meta name="author" content="Chris Wilson">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.min.css">
		<link rel="stylesheet" href="css/theme/default.css" id="theme">

		<!-- For syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- If the query includes 'print-pdf', use the PDF print sheet -->
		<script>
			document.write( '<link rel="stylesheet" href="css/print/' + ( window.location.search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">' );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
		<style>
		pre { font-size: 24px !important; line-height: 1.3 !important;}
		</style>
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
    <section>
        <h1>Making The Web Rock</h1>
        <h2>Web Audio</h2>
        <div>
            <br>
        </div>
        <h3>
            <a target="_new" href="http://cwilso.com/">Chris Wilson</a> / <a target="_new" href="http://twitter.com/cwilso">@cwilso</a>
        </h3>
        <h6>Google Chrome Developer Advocate</h6>
    </section>

<!-- basics begin -->
    <section>
        <h2>Why another audio API?</h2>
        <h3>We have &lt;audio&gt; already!</h3>
        <div>
            <br>
        </div>
		<p>&lt;audio&gt; hides the steps of loading, decoding and playing</p>
		<pre><code>&lt;audio controls src="mysound.ogg"&gt;&lt;/audio&gt;</code></pre>
    </section>

    <section>
        <h2>Sometimes that's the right thing!</h2>
        <div>
            <br>
        </div>
            <audio controls src="glass-hit.ogg"></audio>
    </section>

    <section>
        <h2>Web Audio provides:</h2>
        <div>
            <br>
        </div>
        <div>
            1) <a target="_birds" href="http://chrome.angrybirds.com/">Precise timing</a> of <b>lots</b> of overlapping sounds
        </div>
    </section>

    <section>
        <h2>Web Audio provides:</h2>
        <div>
            <br>
        </div>
        <div>
            2) An audio pipeline/routing system for effects and filters 
        </div>
    </section>

    <section>
        <h2>Web Audio provides:</h2>
        <div>
            <br>
        </div>
        <div>
            3) Hooks to analyze and <a target="_mediademo" href="mediademo/">visualize</a> audio data on the fly
        </div>
    </section>

<!-- basics end -->

    <section>
        <h2>DEMO</h2>
        <div>
            <a target="_vocoder" href="../Vocoder/index.html">Vocoder</a>
        </div>
    <div>(Analysis, Filtering, Visualization)</div>
    </section>

    <section>
        <h2>What is audio useful for, anyway?</h2>
        <div>
            <br>
        </div>
        <div>
            <ul>
                <li>Gaming</li>
                <li>Application UI feedback</li>
                <li>Musical applications</li>
                <li>Audio education</li>
                <li>Audio processing</li>
            </ul>
        </div>
    </section>
    <section>
        <h2>Building Simple App/Game Audio is easy</h2>
		<div>
            <br>
        </div>
		<div>
		    <ul>
		        <li>Load audio files with XHR</li>
		        <li>Tell Web Audio to decode them into buffers</li>
		        <li>Create source node, point at buffer, connect it</li>
                <li>Call <code><font color="#0099cc">start()</font></code>!</li>
		    </ul>
		</div>
	</section>

    <section>
        <h2>Loading and Playing a Sound</h2>
        <div>
            <br>
        </div>
        <pre>var myBuffer = null, context = new AudioContext();

function loadDogSound(url) {
    var request = new XMLHttpRequest();
    request.open("GET", "dogBarking.mp3", true);
    request.responseType = "arraybuffer";
    request.onload = function() {
    context.decodeAudioData( request.response, 
        function(buffer) { myBuffer = buffer;  } ); }
    request.send();
}

function playSound( buffer ) {
    var sourceNode = audioContext.createBufferSource();
    sourceNode.buffer = myBuffer;
    sourceNode.connect( audioContext.destination );
    sourceNode.start( 0 );
}</pre>
    </section>


    <section>
        <h2>Web Audio API is based on a graph</h2>
        <div>
            <br>
        </div>
        <div><!--TODO: draw a graph here--><a target="_playground" href="../../WebAudioPlayground/">webaudioplayground.appspot.com</a></div>
    </section>

    <section>
        <h2>Web Audio minimizes glitching</h2>
        <div>
            <br>
        </div>
        <p>Web Audio runs in a separate thread, <br>so audio and graphics don't compete as much.</p>
        <p>&nbsp;</p>
        <p>You schedule Web Audio events in the future, <br>and the system takes care of them.</p>
    </section>

<section>
    <h2>Scheduling Sound Playback</h2>
    <div>
		<pre>function playEverySecondForTenSeconds( myBuffer ) {
    for (var i=0; i&lt;10; i++) {
        var sourceNode = context.createBufferSource();
        sourceNode.buffer = myBuffer;
        sourceNode.connect( context.destination );
        sourceNode.start( context.now + i );
    }
}</pre>
    </div>
</section>


<section>
    <h2>Scheduling in a complex world</h2>
    <div>
        <br>
    </div>
    <div>For dynamic rhythms, you need to combine web audio and system timing. See <a target="_article" href="http://www.html5rocks.com/en/tutorials/audio/scheduling/">article</a>.</div>
</section>

<section>
    <h2>DEMO</h2>
    <div>
        <a target="_drums" href="../MIDIDrums/index.html">Drum Machine</a>
    </div>
</section>

    <section>
        <h2>Scheduling in Web Audio</h2>
        <div>
            <br>
        </div>
        <div>Not just about start( time )!</div>
        <div>
            <br>
        </div>
        <div>ANY AudioParam can be scheduled -</div>
        <div>frequency, gain, detune, delayTime...</div>
    </section>

    <section>
        <h2>Scheduling on AudioParams</h2>
        <div>
            <br>
        </div>
        <pre>interface AudioParam {  
    attribute value; 

    // Parameter automation
    void setValueAtTime( value, time ); 
    void linearRampToValueAtTime( value, time ); 
    void exponentialRampToValueAtTime( value, time );  
    void setTargetAtTime( target, time, timeConstant );  
    void setValueCurveAtTime( values, time, duration ); 
    void cancelScheduledValues( startTime );  
} </pre>
    </section>

    <section>
        <h2>Gain Fade Example</h2>
        <div>
            <br>
        </div>
        <pre>var envelope = context.createGain();
mySoundNode.connect( envelope );
envelope.connect( context.destination );

var now = context.currentTime;
envelope.gain.setValueAtTime( 0, now );
envelope.gain.linearRampToValueAtTime( 1.0, now + 2.0 );
envelope.gain.linearRampToValueAtTime( 0.0, now + 4.0 );

mySoundNode.start(0);</pre>
    </section>

    <section>
        <h2>Effects in Web Audio</h2>
		<div>
		    <br>
		</div>
		<div>
		    <ul>
		        <li>Biquad Filtering - lowpass, hipass, etc.</li>
                <li>Delays and delay effects</li>
                <li>Waveform synthesis: oscillators</li>
                <li>Envelopes</li>
                <li>Offline processing</li>
		        <li>Compression</li>
		        <li>Convolution</li>
		        <li>Waveshaping</li>
		        <li>Positioning/Panning/Doppler</li>
                <li>Custom Javascript processing</li>
		    </ul>
		</div>
	</section>

	<section>
	    <h2>Audio for Music Applications</h2>
	    <div>Most "musical effects" are more complex than <br>just a single filter or delay.</div>
        <div>
            <br>
	    </div>
	    <div>AudioParams can also be driven by audio-rate signals - <br>
            a chorus effect is just an oscillator changing delayTime!</div>
	    <div>
	</section>

    <section>
        <h2>DEMO</h2>
        <h4>(you may need headphones for this one, sorry...)</h4>
        <div>
            <a target="_input" href="../input/index.html">Audio Input Effects</a>
        </div>
    </section>

    <section>
        <h2>&lt;audio&gt; Integration</h2>
        <div>Web Audio can also process &lt;audio&gt; streams <br>(and WebRTC, too!)</div>
    </section>

	<section>
	    <h2>Audio Input</h2>
	    <div>Access to audio input devices too!</div>
	    <div>
	        <br>
	    </div>
	    <div>
	        <ul>
	            <li><a target="_record" href="../AudioRecorder/index.html">Recording</a></li>
	            <li>Input-driven UX</li>
	            <li><a target="_tuning" href="../pitchdetect/index.html">Instrument tuning</a></li>
                <li><a target="_tuning" href="https://aerotwist.com/blog/guitar-tuner/">Paul Lewis' Guitar Tuner</a></li>
	            <li>Analysis</li>
	        </ul>
	    </div>
	</section>

    <section>
        <h2>DEMO</h2>
        <div>Building a <a target="_synth" href="../midi-synth/index.html">Synthesizer</a></div>
    </section>

    <section>
        <h2>Controlling it All</h2>
        <div>
            <br>
        </div>
        <div>Web MIDI : <a href="http://webaudio.github.io/web-midi-api/">webaudio.github.io/web-midi-api/</a></div>
        <div><a href="http://webaudio.github.com/WebMIDI">Developing standard</a> - Shipping in Chrome, Firefox developing implementation, and I wrote a cross-browser plugin-based <a href="http://github.com/cwilso/WebMIDIAPIShim/">polyfill.</a></div>
    </section>
    <section>
        <h2>Web MIDI</h2>
        <div>
            <br>
        </div>
        <div>This is not cheesy background music! &nbsp;</div>
        <div>That's "Standard MIDI files."</div>
        <div>
            <br>
        </div>
        <div>MIDI lets you connect controllers, synthesizers and more to your computer.</div>
    </section>

    <section>
        <h2>CODE</h2>
        <div><br></div>
        <div>So how did I hook up that <a target="_synth" href="../midi-synth/index.html">synthesizer</a>?</div>
    </section>

    <section>
        <h2>Asking for MIDI devices</h2>
        <div>
            <br>
        </div>
        <pre>window.addEventListener('load', function() {   
  navigator.requestMIDIAccess().then( 
    onMIDIInit, 
    onMIDISystemError );
});</pre>
    </section>

    <section>
        <h2>Enumerating MIDI output devices</h2>
        <div>
            <br>
        </div>
        <pre>function onMIDIInit( midi ) {
  for (var input of midiAccess.outputs.values())
    input.send( [0x90, 3, 32] );
}
</pre>
    </section>

    <section>
        <h2>Don't forget hot-plugging MIDI devices!</h2>
        <div>
            <br>
        </div>
        <pre>midiAccess.onstatechange = 
    function midiConnectionStateChange( e ) { populateMIDIInSelect() };</pre>
    </section>

    <section>
        <h2>MIDI Message syntax</h2>
        <div><br></div>
        <div>MIDI has 16 virtual channels, blah blah blah.</div>
        <br>
        <div>MIDI spec:<br>
        <a href="http://www.midi.org/techspecs/midimessages.php">
        http://www.midi.org/techspecs/midimessages.php</a></div>
        <br><div>MIDI note numbers: <br>
        <a href="http://www.phys.unsw.edu.au/jw/notes.html">
        http://www.phys.unsw.edu.au/jw/notes.html</a></div>
    </section>

    <section>
        <h2>Enumerating MIDI input devices</h2>
        <div>
            <br>
        </div>
        <pre>function onMIDIInit( midi ) {
  for (var input of midiAccess.inputs.values())
    input.onmidimessage = midiMessageReceived;
}
</pre>
    </section>

    <section>
        <h2>Parsing MIDI messages</h2>
        <div>
            <br>
        </div>
        <pre>function midiMessageReceived( ev ) {
    var cmd = ev.data[0] >> 4;
    var channel = ev.data[0] &amp; 0xf;
    var noteNumber = ev.data[1];
    var velocity = 0;
    if (ev.data.length > 2)
      velocity = ev.data[2];

    // MIDI noteon with velocity=0 is the same as noteoff
    if ( cmd==8 || ((cmd==9)&amp;&amp;(velocity==0)) ) { // noteoff
      noteOff( noteNumber );
    } else if (cmd == 9) { // note on
      noteOn( noteNumber, velocity);
    } else if (cmd == 11) { // controller message
      controller( noteNumber, velocity);
    } else {
      // probably sysex!
    }
}</pre>
    </section>

    <section>
        <h2>DEMO</h2>
        <div><br></div>
        <div>Spinning the discs - <a target="_wubwubwub_" href="../wubwubwub/index.html">wubwubwub</a></div>
    </section>

    <section>
        <h2>The Incredible Thing about Web MIDI</h2>
        <div>ZERO-FRICTION <a target="_organ" href="http://www.farfisaofthefuture.com/">controller</a> and device access!
    </section>

    <section>
        <h2><a href="http://yamahasynth.com">Yamaha's Reface series</a></h2>
        <img src="reface.jpg">
    </section>

    <section>
        <h2><a href="http://peavey.com/products/vypyr/">Peavey's VYPYR series of guitar amps</a></h2>
        <img src="vyper2.jpg">
    </section>

    <section>
        <h2>Web MIDI support</h2>
        <div>Shipping in Chrome</div>
        <div>Works on Android Chrome with USB OTG! </div>
        <div>Firefox is <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=836897">actively working on it</a>.</div>
    </section>

    <section>
        <h2>Web Audio Support on Desktop</h2>
        <div>Chrome, Safari, Firefox, Edge</div>
    </section>

    <section>
        <h2>Web Audio Support on Mobile</h2>
        <div>Chrome for Android has support (higher latency)</div>
        <div>iOS Safari 6.0 has Web Audio (with some caveats)</div>
        <div>FFOS</div>
    </section>

    <section>
        <h2>Future App Opportunities</h2>
        <div>
            <ul>
                <li>Immersive gaming audio</li>
                <li>Audio feedback and input in app UX</li>
                <li>Audio education - <a target="_new" href="http://outputchannel.com/post/tr-808-cowbell-web-audio/">explore techniques</a>, share with others
                </li>
                <li><span style="color:orange">Super-low-friction music applications - synthesis to DAW</span>
                </li>
            </ul>
        </div>
    </section>

    <section>
        <h2>What's NOT there (yet) for web audio</h2>
        <ul>
        <li>Any kind of plugin/VSTi hooks
        <li>Multi-interface hooks<br>(multi-channel, partly; multi-device, no.)
        </ul>
    </section>

    <section>
        <h2> Next Things for Web Audio &amp; Web MIDI</h2>
        <div>
            <ul>
                <li>Audio Workers (processing audio in JS)</li>
                <li>Figuring out device access and selection</li>
                <li>latency alignment</li>
                <li>Finalizing v1</li>
                <li>Low-level access to audio stream and resampling</li>
            </ul>
        </div>
    </section>

    <section>
        <h2>Other Demos</h2>
        <ul>
        <li>Immersive, low-friction MIDI: <a target="_midispace" href="http://midi.space/">midi.space/</a>
        <li>Farfisa Organ: <a href="http://www.farfisaofthefuture.com/">http://www.farfisaofthefuture.com/</a>
        <li>Soundtrap (DAW): <a href="https://www.soundtrap.com/">https://www.soundtrap.com/</a>
        <li>Audio Looper: <a target="_looperjs" href="https://github.com/lautr3k/Looper.js">https://github.com/lautr3k/Looper.js</a>
        <li>Yamaha's Web Music Platform OS project: <a href="yamaha-webmusic.github.io/webmusicplatform/app/">yamaha-webmusic.github.io/webmusicplatform/app/</a>
        <li>Noteflight (notation): <a target="_noteflight" href="http://noteflight.com/"
        <li>Yamaha's NSX1 apps: <a href="yamaha-webmusic.github.io">yamaha-webmusic.github.io</a>
        <li>Synth setups<a  target="_hya" href="http://app.hya.io/">http://app.hya.io/</a>
        <li>Drawing a waveform: <a target="_waviator" href="http://milesofdata.com/waviator/">http://milesofdata.com/waviator/</a>
        <li>Visualization: <a target="_spirals" href="http://tomasgonzalezvivo.com/soundspirals/">http://tomasgonzalezvivo.com/soundspirals/</a>
        </ul>
    </section>


<section>
    <h2>Web Audio Weekly</h2>
    <div>If you're not already reading Chris Lowis' Web Audio Weekly, you should.</div>
    <div><a href="tinyletter.com/webaudioweekly">tinyletter.com/webaudioweekly</a></div>
</section>

<section>
        <h2>What I want from you:</h2>
        <ul>
        <li>More developers to explore Web Audio and Web MIDI
        <li>Tell us what's not there
        <li>Help us prioritize to make the web platform awesome for audio apps!
        <li>Explore audio techniques and share with others
        </ul>
        </section>

    <section>
        <h2>End</h2>
        <div>
            <br>
        </div>
        <div>Questions?</div>
        <div>
            <br>
        </div>
        <div>cwilso@google.com</div>
        <div>@cwilso</div>
        <div><a href="http://github.com/cwilso">github.com/cwilso</a></div>
        <div><a href="http://webaudiodemos.appspot.com/">webaudiodemos.appspot.com</a></div>
        <div>+Chris Wilson</div>
        <div>These slides:<a href="http://webaudiodemos.appspot.com/slides/index.html">goo.gl/iCsRY</a></div>
    </section>



			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.min.js"></script>

		<script>

			// Full list of configuration options available here:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
				transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

				// Optional libraries used to extend on reveal.js
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/showdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
					// { src: 'plugin/search/search.js', async: true, condition: function() { return !!document.body.classList; } }
					// { src: 'plugin/remotes/remotes.js', async: true, condition: function() { return !!document.body.classList; } }
				]
			});

		</script>

	</body>
</html>
