<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Making the Web Rock: Web Audio</title>

		<meta name="description" content="Web Audio talk">
		<meta name="author" content="Chris Wilson">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.min.css">
		<link rel="stylesheet" href="css/theme/default.css" id="theme">

		<!-- For syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
		<style>
        h2 { text-transform: capitalize !important;  }
        .delete {text-decoration: line-through;}
		</style>
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
    <section>
        <h1>Making The Web Rock</h1>
        <h2>Web Audio</h2>
        <div>
            <br>
        </div>
        <div class="delete">
            <div>Chris Wilson / @cwilso</div>
            <div>Google Chrome Developer Advocate</div>
        </div>
        <div>
            <small>The keynote is modified from this guy's version ðŸ‘†</small>
        </div>
        <h3>
            <a target="_new" href="https://hk1229.cn/">Kyle He</a> /
            <a target="_new" href="http://twitter.com/kyleehee">@kyleehee</a>
        </h3>
    </section>

<!-- basics begin -->
<section>
    <section>
        <h2>Why another audio API?</h2>
        <h3>We have &lt;audio&gt; already!</h3>
        <div>
            <br>
        </div>
        <p>&lt;audio&gt; hides the steps of loading, decoding and playing</p>
        <pre><code>&lt;audio controls src="mysound.ogg"&gt;&lt;/audio&gt;</code></pre>
    </section>

    <section>
        <h2>Sometimes that's the right thing!</h2>
        <div>
            <br>
        </div>
            <audio controls src="glass-hit.ogg"></audio>
    </section>

</section>

<section>
    <section>
        <h2>Web Audio provides:</h2>
        <div>
            <br>
        </div>
        <div>
            1) Precise timing of <b>lots</b> of overlapping sounds
        </div>
    </section>

    <section>
        <h2>Web Audio provides:</h2>
        <div>
            <br>
        </div>
        <div>
            2) An audio pipeline/routing system for effects and filters
        </div>
    </section>

    <section>
        <h2>Web Audio provides:</h2>
        <div>
            <br>
        </div>
        <div>
            3) Hooks to analyze and <a target="_blank" href="mediademo/index.html">visualize</a> audio data on the fly
        </div>
    </section>

    <section>
        <h2>DEMO</h2>
        <div>
            <a target="_blank" href="https://webaudiodemos.appspot.com/Vocoder/index.html">Vocoder</a>
        </div>
        <div>(Analysis, Filtering, Visualization)</div>
    </section>
</section>


    <section>
        <h2>What is audio useful for, anyway?</h2>
        <div>
            <br>
        </div>
        <div>
            <ul>
                <li>Gaming</li>
                <li>Application UI feedback</li>
                <li>Musical applications</li>
                <li>Audio education</li>
                <li>Audio processing</li>
            </ul>
        </div>
    </section>


    <section>

        <section>
            <h2>Web Audio API is based on a graph</h2>
            <div><img src="https://mdn.mozillademos.org/files/12241/webaudioAPI_en.svg"></div>

            <div>
                <br>
                <a target="_blank" href="http://webaudioplayground.appspot.com/">Playground</a>
            </div>
        </section>

        <section>
            <h2>Build</h2>
            <div><pre><code>var audioHtmlElement = document.querySelector('audio')
var audioContext = new AudioContext()
var sourceNode = audioContext.createMediaElementSource(audioHtmlElement);
sourceNode.buffer = audioBuffer;
sourceNode.connect( audioContext.destination );
sourceNode.start();</code></pre></div>
        </section>

        <section>
            <div>
                <h2>Audio Source</h2>
            </div>
            <div>
                <ul>
                    <li>audioContext.create<u>BufferSource</u>()</li>
                    <li>audioContext.create<u>MediaStreamSource</u>()</li>
                    <li>audioContext.create<u>MediaElementSource</u>()</li>

                    <li>audioContext.create<u>Oscillator</u>()</li>
                </ul>
            </div>
        </section>

        <section>
            <div>
                <h2>Audio Destination</h2>
            </div>
            <div>
                <ul>
                    <li>audioContext.<u>destination</u>()</li>
                    <li>audioContext.create<u>MediaStreamDestination</u>()</li>
                </ul>
            </div>
        </section>

        <section>
            <h2>Loading and Playing a Sound</h2>
            <div>
                <br>
            </div>
            <pre><code data-trim data-noescape>var myBuffer = null, context = new AudioContext();

function loadDogSound(url) {
    var request = new XMLHttpRequest();
    request.open("GET", "dogBarking.mp3", true);
    request.responseType = "arraybuffer";
    request.onload = function() {
    context.decodeAudioData( request.response,
        function(buffer) { myBuffer = buffer;  } ); }
    request.send();
}

function playSound( buffer ) {
    var sourceNode = audioContext.createBufferSource();
    sourceNode.buffer = myBuffer;
    sourceNode.connect( audioContext.destination );
    sourceNode.start( 0 );
}</code></pre>
        </section>

        <section>
            <h2>MediaStreamSource</h2>
            <div>
                <br>
            </div>
            <h4>UserMedia</h4>
            <pre><code data-trim data-noescape>navigator.getUserMedia({
    audio: true,
    video: true
}, function(stream) {
    var source = audioCtx.createMediaStreamSource(stream);</code></pre>

            <h4>WebRTC</h4>
            <pre><code data-trim data-noescape>var dest = ac.createMediaStreamDestination();
var mediaRecorder = new MediaRecorder(dest.stream);</code></pre>
        </section>

        <section>
            <h2>Oscillator</h2>
            <pre><code data-trim data-noescape>var oscillator = audioCtx.createOscillator();

// sine, square, sawtooth, triangle, custom
oscillator.type = 'square';

oscillator.frequency.value = 3000; // value in hertz
oscillator.start();</code></pre>
        </section>

        <section>
            <h2>Periodic Wave</h2>
            <div><img src="img/basic-time-domain-waveform.png"></div>
            <pre><code data-trim data-noescape>var real = new Float32Array(2);
var imag = new Float32Array(2);
real[0] = 0; imag[0] = 0;
real[1] = 1; imag[1] = 0;

var wave = audioContext.createPeriodicWave(real, imag, {
    disableNormalization: true
});
oscillator.setPeriodicWave(wave);</code></pre>
        </section>

    </section>


<section>
    <section>
        <h2>audio effects filters</h2>
        <div><img src="https://mdn.mozillademos.org/files/9713/WebAudioBasics.png"></div>

        <div>
            <br>
            DEMO:
            <a target="_blank" href="https://webaudiodemos.appspot.com/midi-synth/index.html">"Analog" Synthesizer</a>
        </div>
    </section>


    <section>
        <h2>Audio Volume Control</h2>
        <div>
            <img src="https://mdn.mozillademos.org/files/5085/WebAudioGainNode.png">
        </div>
        <pre><code>var gainNode = audioContext.createGain();
sourceNode.connect( gainNode );
gainNode.connect( audioContext.destination );

function toggleMuted() {
    gainNode.gain.value = gainNode.gain.value ? 0 : 1
}</code></pre>
    </section>

    <section>
        <h2>Effects in Web Audio</h2>
        <div>
            <br>
        </div>
        <div>
            <ul>
                <li>Biquad Filtering - lowpass, hipass, etc.</li>
                <li>Delays and delay effects</li>
                <li>Compression</li>
                <li>Convolution</li>
                <li>Waveshaping</li>
                <li>Positioning/Panning/Doppler</li>
                <li>Custom Javascript processing</li>
                <li><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API#Defining_audio_effects_filters" target="_blank">...</a></li>
            </ul>
        </div>
        <div>
            <a target="_blank" href="http://webaudioplayground.appspot.com/">Playground</a>
        </div>
    </section>

</section>

<section>
    <section>
        <h2>Channels</h2>
        <div style="display: flex; justify-content: space-around;">
            <div>
                <img src="https://mdn.mozillademos.org/files/5255/WebAudioSplitter.png">
                <div>ChannelSplitterNode</div>
            </div>
            <div>
                <img src="https://mdn.mozillademos.org/files/9709/WebAudioMerger.png">
                <div>ChannelMergerNode</div>
            </div>
        </div>
    </section>
    <section>
        <pre><code>var splitter = audioContext.createChannelSplitter(2);
    var merger = audioContext.createChannelMerger(2);
    source.connect(splitter);

    // Reduce the volume of the left channel only
    var gain = audioContext.createGain();
    gain.value = 0.5;
    splitter.connect(gain, 0);

    gain.connect(merger, 0, 1);
    splitter.connect(merger, 1, 0);

    merger.connect(audio.destination);
});</code></pre>
    </section>
</section>


<section>
    <h2>Web Audio minimizes glitching</h2>
    <div>
        <br>
    </div>
    <p>Web Audio runs in a separate thread, <br>so audio and graphics don't compete as much.</p>
    <p>&nbsp;</p>
    <p>You schedule Web Audio events in the future, <br>and the system takes care of them.</p>
</section>

<section>

    <section>
        <h2>Scheduling Sound Playback</h2>
        <div>
    		<pre><code data-trim data-noescape>function playEverySecondForTenSeconds( myBuffer ) {
    for (var i=0; i&lt;10; i++) {
        var sourceNode = context.createBufferSource();
        sourceNode.buffer = myBuffer;
        sourceNode.connect( context.destination );
        sourceNode.start( context.now + i );
    }
}</code></pre>
        </div>
    </section>


    <section>
        <h2>Scheduling in a complex world</h2>
        <div>
            <br>
        </div>
        <div>For dynamic rhythms, you need to combine web audio and system timing. See
            <a target="_article" href="http://www.html5rocks.com/en/tutorials/audio/scheduling/">article</a>
        </div>

        <div>
            <br>
            DEMO: <a target="_blank" href="https://webaudiodemos.appspot.com/MIDIDrums/index.html">Drum Machine</a>
        </div>
    </section>

    <section>
        <h2>Scheduling in Web Audio</h2>
        <div>
            <br>
        </div>
        <div>Not just about start( time )!</div>
        <div>
            <br>
        </div>
        <div>ANY AudioParam can be scheduled -</div>
        <div>frequency, gain, detune, delayTime...</div>
    </section>

    <section>
        <h2>Scheduling on AudioParams</h2>
        <pre><code data-trim data-noescape>interface AudioParam {â€¨â€¨
    attribute value;â€¨

    // Parameter automation
    void setValueAtTime( value, time );â€¨
    void linearRampToValueAtTime( value, time );â€¨
    void exponentialRampToValueAtTime( value, time );â€¨â€¨
    void setTargetAtTime( target, time, timeConstant );â€¨â€¨
    void setValueCurveAtTime( values, time, duration );â€¨
    void cancelScheduledValues( startTime );â€¨â€¨
}â€¨</code></pre>
        <div>
            <a href="http://mdn.github.io/audio-param/" target="_blank">DEMO</a>
        </div>
    </section>

    <section>
        <h2>Gain Fade Example</h2>
        <div>
            <br>
        </div>
        <pre><code>var envelope = context.createGain();
mySoundNode.connect( envelope );
envelope.connect( context.destination );

var now = context.currentTime;
envelope.gain.setValueAtTime( 0, now );
envelope.gain.linearRampToValueAtTime( 1.0, now + 2.0 );
envelope.gain.linearRampToValueAtTime( 0.0, now + 4.0 );

mySoundNode.start(0);</code></pre>
    </section>
</section>


<section>
    <section>
        <h2>AnalyserNode</h2>
        <div>
            <img style="background: white;"
                src="https://mdn.mozillademos.org/files/12970/fttaudiodata_en.svg">
        </div>
        <div>
            DEMO:
            <a href="https://webaudiodemos.appspot.com/input/index.html" target="_blank">Visualizer</a>
        </div>
    </section>

    <section>
        <ul>
            <li>AudioContext.<u>createAnalyser</u>()</li>
            <li>-------</li>
            <li>AnalyserNode.<u>fftSize</u></li>
            <li>AnalyserNode.<u>frequencyBinCount</u></li>
            <li>-------</li>
            <li>AnalyserNode.getFloatFrequencyData()</li>
            <li>AnalyserNode.getByteFrequencyData()</li>
            <li>AnalyserNode.getFloatTimeDomainData()</li>
            <li>AnalyserNode.getByteTimeDomainData()</li>
        </ul>
    </section>

    <section>
        <h2>Time Domain Graph</h2>
        <div><pre><code>var analyser = audioCtx.createAnalyser();
analyser.fftSize = 2048;
var bufferLength = analyser.frequencyBinCount;
var dataArray = new Uint8Array(bufferLength);

function draw() {
    analyser.getByteTimeDomainData(dataArray);

    canvasCtx.fillStyle = 'rgb(200, 200, 200)';
    canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

    canvasCtx.lineWidth = 2;
    canvasCtx.strokeStyle = 'rgb(0, 0, 0)';

    canvasCtx.beginPath();

    var sliceWidth = WIDTH * 1.0 / bufferLength;
    var x = 0;

    for(var i = 0; i < bufferLength; i++) {

        var v = dataArray[i] / 128.0;
        var y = v * HEIGHT / 2;

        if(i === 0) {
            canvasCtx.moveTo(x, y);
        } else {
            canvasCtx.lineTo(x, y);
        }

        x += sliceWidth;
    }

    canvasCtx.lineTo(canvas.width, canvas.height/2);
    canvasCtx.stroke();

    requestAnimationFrame(draw);
}

draw();</code></pre></div>
    </section>

    <section>
        <h2>Frequency Domain Graph</h2>
        <div><pre><code>function draw() {
    canvasCtx.clearRect(0, 0, WIDTH, HEIGHT)
    analyser.getByteFrequencyData(dataArray)

    let barWidth = WIDTH / bufferLength
    let barHeight
    let left = 0
    for (let i = 0; i < bufferLength; i++) {
        barHeight = dataArray[i] / 256 * HEIGHT
        canvasCtx.fillRect(left, HEIGHT - barHeight, barWidth, barHeight)
        left += barWidth
    }

    requestAnimationFrame(draw);
}</code></pre></div>
    </section>
</section>

<section>
    <section>
        <h2>ScriptProcessorNode</h2>
        <div>
            <img src="https://mdn.mozillademos.org/files/5157/WebAudioScriptProcessingNode.png">
        </div>
    </section>

    <section>
        <div><pre><code>var scriptNode = audioCtx.createScriptProcessor(4096, 1, 1);
scriptNode.onaudioprocess = function(audioProcessingEvent) {
    var inputBuffer = audioProcessingEvent.inputBuffer;

    var outputBuffer = audioProcessingEvent.outputBuffer;

    for (var channel = 0; channel < outputBuffer.numberOfChannels; channel++) {
        var inputData = inputBuffer.getChannelData(channel);
        var outputData = outputBuffer.getChannelData(channel);

        for (var sample = 0; sample < inputBuffer.length; sample++) {
            outputData[sample] = inputData[sample];

            outputData[sample] += ((Math.random() * 2) - 1) * 0.2;
        }
    }
}</code></pre></div>
    </section>
</section>


<section>
    <h2>Homework?</h2>
    <p>Diy your own Virtual <a href="https://www.wikiwand.com/en/Theremin">Theremin</a></p>
    <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/YdCfBpNlEgA"
            frameborder="0" allowfullscreen></iframe>
    </div>
</section>

<section>
    <h2>Web MIDI API next time?</h2>
    <div><br></div>
    <div>
        <a href="https://cdn.adeline.cc/pay/" target="_blank">Donate</a>
        to me first so that I can buy a MIDI device later. ðŸ˜‚
    </div>
</section>

<section>
    <h2>End</h2>
    <div>
        <br>
    </div>
    <div>Questions?</div>
    <div>
        <br>
    </div>
    <div><a href="http://webaudiodemos.appspot.com/">Demo Collection</a></div>
</section>

			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.min.js"></script>

		<script>

			// Full list of configuration options available here:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: false,
				history: true,
				center: true,

				theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
				transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

				// Optional libraries used to extend on reveal.js
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/showdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
					// { src: 'plugin/search/search.js', async: true, condition: function() { return !!document.body.classList; } }
					// { src: 'plugin/remotes/remotes.js', async: true, condition: function() { return !!document.body.classList; } }
				]
			});

		</script>

	</body>
</html>
